## Contents
+ [규칙기반 및 통계 기반 자연어처리](#규칙-기반-및-통계-기반-자연어처리)  
+ [기계학습 및 딥러닝 기반 자연어처리](#기계학습-및-딥러닝-기반-자연어처리)  
+ [뉴럴 심볼릭 기반 자연어처리](#뉴럴-심볼릭-기반-자연어처리)    
+ [Pretrain-Finetuning 기반 자연어처리](#Pretrain-Finetuning-기반-자연어처리)
+ [LLM (Large Language Models) 기반 자연어처리](#LLM-(Large-Language-Models)-기반-자연어처리)
+ [Continual Learning (연속 학습)](#Continual-Learning-(연속-학습))    
+ [NLP에서 윤리와 공정성(Ethics & Fairness)](#NLP에서-윤리와-공정성(Ethics-&-Fairness))    


<br />

# 규칙기반 및 통계 기반 자연어처리

## 규칙 기반 NLP

- 언어학적 규칙을 전문가가 직접 정의하여 모델을 설계

- 형태소 분석, 구문 분석, 의미 분석 등에서 사용됨

- 단점: 확장성이 낮고, 새로운 데이터에 적응 어려움

## 통계 기반 NLP

- 대량의 텍스트 데이터를 학습하여 패턴을 찾고 통계를 기반으로 모델 구축

- 단어의 분산 표현(Word Embedding)을 활용

- 통계적 언어 모델(SLM): 다음 단어를 확률적으로 예측

<br />

# 기계학습 및 딥러닝 기반 자연어처리

## 머신러닝 (Machine Learning, ML)

- 지도학습 (Supervised Learning): NER, 감성 분석 등에 사용

- 비지도학습 (Unsupervised Learning): 군집화, 차원 축소 등에 사용

## 딥러닝 (Deep Learning, DL)

- RNN, LSTM, Transformer 기반 모델 활용

- 딥러닝이 규칙 기반을 뛰어넘음 -> 전문가의 개입 없이 자동으로 패턴 학습

<br />

# 뉴럴 심볼릭 기반 자연어처리

## 뉴럴 심볼릭 (Neural Symbolic)

- 딥러닝(뉴럴 네트워크) + 기호 기반(심볼릭) 지식을 결합하여 모델의 논리적 추론 능력 강화

- 지식 그래프(Knowledge Graph)를 이용하여 상식 및 추론 능력 보완

- ex) KG-BERT (Knowledge Graph + BERT)

<br />

# Pretrain-Finetuning 기반 자연어처리

## 사전학습(Pretraining)과 미세조정(Finetuning)

- Pretraining: 대량의 데이터로 일반적인 언어 능력을 학습 ex) BERT, GPT

- Finetuning: 특정 태스크에 맞게 추가 학습

## Transformer 기반 언어 모델 발전

- BERT(인코더), GPT(디코더), BART(인코더-디코더) 등 다양한 모델 등장

- 벤치마크(Leaderboard)에서 성능 경쟁 활성화

<br />

# LLM (Large Language Models) 기반 자연어처리

## 대규모 언어 모델 (LLM)의 특징

- 모델 크기가 클수록 성능이 좋아짐 (Scaling Laws)

- 데이터보다 모델 크기가 더 중요한 성능 요소

## 주요 LLM 모델

- GPT-3 (175B 파라미터, OpenAI)

- PaLM (Google)

- LLaMA (Meta)

- HyperCLOVA (Naver)

- EXAONE (LG)

## Prompt Engineering & In-Context Learning

- Few-shot Learning: 몇 개의 예시만으로도 성능 향상

- Instruction Tuning & RLHF (ChatGPT처럼 사용자 피드백 반영)

<br />

# Continual Learning (연속 학습)

## LLM이 지속적으로 학습하는 방식

- 새로운 데이터를 추가 학습하면서 기존 지식을 유지

- 문제점: Catastrophic Forgetting (기존 정보 손실)

<br />

# NLP에서 윤리와 공정성(Ethics & Fairness)

## AI의 편향 문제

- 데이터셋에 존재하는 성별, 인종, 문화적 편향이 모델에 영향을 줌

- ex) 번역 모델이 "간호사 -> 여성"으로 자동 변환하는 문제

## 해결 방법

- Bias Mitigation 기법 적용 (ex. Fair NLP 연구)

- 기계번역 품질 예측(QE) 및 치명적 오류 감지