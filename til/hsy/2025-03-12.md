# Contents
- [자연어 처리 평가지표](#자연어-처리-평가지표)
- [자언여 처리 Pipeline](#자언여-처리-pipeline)

<br>

# 자연어 처리 평가지표

## 분류 모델 평가 - Confusion Matrix

<br>

|실제값\예측값|긍정 (P)|부정 (N)|
|------|---|---|
|긍정 (P)|True Positive (TP)|False Negative (FN)|
|부정 (N)|False Positive (FP)|True Negative (TN)|

<br>

- 정확도 (Accuracy) = (TP + TN) / (TP + FP + FN + TN)
    
    - 모델이 예측한 것들 중에 (실제와) 일치한 것 비율

- 정밀도 (Precision) = TP / (TP + FP) 

    - 모델이 "긍정"이라고 예측한 것 중 실제 긍정인 비율

- 재현율 (Recall) = TP / (TP + FN)

    - 실제 긍정 중 모델이 "긍정"이라고 예측한 비율

- F1-socre = Precision과 Recall의 조화 평균

<br>

## 기계 번역 평가 - BLEU Score

- 번역된 문장이 얼마나 정답과 유사한지 평가하는 지표

- n-gram(2~4개 단어 묶음) 단위로 정답과 비교하여 정확도를 측정

- 번역 Task에서 정답문장(reference) 중 몇 단어가 빠져도 (recall이 떨어져도) 문장의 의미가 유사할 수 있지만, 문장에 없는 단어가 오역되어 들어오면 (precision이 떨어지면) 영향이 클 수 있기 때문에 recall이 아닌 precision을 기반으로 함

<br>

- 예시 1)

    - Reference : ```"I went to the park yesterday and saw a dog."```
    - Predicted : ```"I went to the park and saw a dog."```

    ![Evaluation Metrics 1](https://velog.velcdn.com/images%2Fbo-lim%2Fpost%2F9d9141ef-72b6-48c3-8d41-5e194db8f9ba%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202022-03-14%20%EC%98%A4%ED%9B%84%202.59.11.png)

<br>

- 예시 2)

    - Reference : ```"I went to the park yesterday and saw a dog."```
    - Predicted : ```"a saw and yesterday the to park went I dog."```

    -> 위의 예시에서는 순서가 전혀 맞지 않지만 Precision, recall, F-measure 모두 100%가 됨

<br>

- 예시 3)

    - model 1 : ```"I went in the park today and saw a cat."``` (부분적으로 올바른 단어 포함, 일부 순서 오류)
    - model 2 : ```"dog a saw and yesterday park the to went I."``` (단어는 같지만 순서가 완전히 다름)

    - ```brevity penalty```: reference 문장보다 짧은 예측 문장을 내놓을 시, 1 이하의 값을 곱해서 precision 값을 낮게 보정함

    ![Evaluation Metrics 2](https://velog.velcdn.com/images%2Fbo-lim%2Fpost%2F0be505ba-8a31-4630-b5be-587ecc61fdb6%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202022-03-14%20%EC%98%A4%ED%9B%84%203.33.36.png)

<br><br>

# 자언여 처리 Pipeline

## 1. 데이터 수집 & 전처리

- 데이터셋 로드

    - CSV 파일을 ```"pandas"```를 사용해 불러옴

    - ```"train.csv"```, ```"test.csv"``` 파일을 로드하고 학습/검증 데이터로 나눔

- 토크나이징 (Tokenizing)

    - 문장을 모델이 이해할 수 있도록 단어 단위 또는 서브워드 단위로 변환

    - ```"Hugging Face"```의 사전 학습된 토크나이저를 활용하여 빠르고 효율적으로 토큰화

<br>

## 2. 모델 학습

- 사전 학습된 모델(Pre-trained Model) 로드

    - ```"Hugging Face"```에서 사전 학습된 Transformer 모델을 불러옴

    - ex. ```"bert-base-uncased"```, ```"distilbert-base-multilingual-cased"``` 등

- Trainer를 활용한 모델 학습

    - Trainer는 모델을 학습, 평가, 최적화하는 간편한 툴

    - ```"TrainingArguments"```를 설정하여 학습률, 배치 크기, 체크포인트 저장 방식 등을 조절

- Trainer의 주요 기능

    1. 배치 학습 (Batch Learning)

    2. 학습 스케줄러 (Learning Scheduler)

    3. 조기 종료 (Early Stopping) -> 성능이 더 이상 개선되지 않으면 학습 중단

<br>

## 3. 모델 평가 & 추론 (Inference & Evaluation)

- 추론 (Inference)
    
    - 학습된 모델을 ```"modle.eval()"``` 모드로 설정 후, 새로운 데이터를 입력하여 예측 수행

    - ```"troch.no_grad()"```를 사용하여 불필요한 연산을 줄이고 속도를 향상

- 모델 평가 (Evaluation)

    - 모델의 예측값과 실제 정답(Label)을 비교하여 성능을 측정

    - ```"sklearn.metrics"```의 ```"accuracy"```, ```"f1_score"``` 등을 활용하여 정확도 평가