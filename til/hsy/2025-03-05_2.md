## 텍스트 전처리 (Text Preprocessing)

- NLP에서 컴퓨터가 텍스트를 더 잘 이해할 수 있도록 데이터를 정리하고 분석하기 쉬운 형태로 변환하는 과정


### 전처리 (Preprocessing)

- 텍스트 내 불필요한 요소 제거 (HTML 태그, 특수문자, 이모티콘 등) 

- 주요 전처리 방법

    - 정규표현식 (Regex)

    - 불용어 제거 (Stopword)

    - 어간 추출 (Stemming)

    - 표제어 추출 (Lemmatization)


### 토큰화 (Tokenization)

- 텍스트를 작은 단위(토큰)로 나누는 과정

- 종류

    - 문장 토큰화: 문장을 기준으로 분리

    - 단어 토큰화: 단어를 기준으로 분리

    - 형태소 토큰화: 한국어에서 조사 등을 구분하기 위해 사용

- 예시

    "Hello, World!" -> ["Hello", ",", "World", "!"]

- 한국어 토큰화의 어려움

    - 조사(그가, 그를, 그는) -> 같은 단어라도 다른 의미

    - 띄어쓰기 문제 ex) 띄어쓰기를안해도사람들은이해함

    => 형태소 분석기가 필요함 (ex. KoNLPy, Mecab, Komoran 등)


### 정제 (Cleansing)

- 데이터에서 불필요한 요소를 제거하는 과정

- 주요 작업

    - 특수문자 제거, 대소문자 변환, 중복 문구 제거, 다중 공백 통합 등

- 불용어(Stopword) 제거 

    - 분석에 의미가 없는 단어 삭제 (ex. "은", "는", "이", "가", "the", "is" 등)


### 정규화 (Normalization)

- 같은 의미를 가진 단어들을 통일하는 과정

- 어간 추출 (Stemming) vs 표제어 추출 (Lemmatization)

    |구분|어간 추출 (Stemming)|표제어 추출 (Lemmatization)|
    |------|---|---|
    |정의|접사 제거하여 어간을 추출|단어의 원형(lemma)으로 변환|
    |예시|"was" → "was"|"was" -> "be"|
    |정확성|상대적으로 낮음|문맥 고려하여 정확함|

    => 한국어에서는 표제어 추출이 더 적합 (형태소 분석 필요)


### 편집 거리 (Edit Distance)

- 두 문자열이 얼마나 다른지 측정하는 방법 

- 레벤슈타인 거리 (Levenshtein Distance) 라고도 함

- 방법

    - 문자 삭제(Delete) ex. "점심을먹자" -> "점심먹자"

    - 문자 추가(Insert) ex. "점심먹자" -> "점심을먹자"

    - 문자 변경(Substitution) ex. "점심먹자" -> "점심먹장"


### 정규표현식 (Regex)

- 특정한 패턴을 가진 문자열을 찾거나 변환하는 데 사용